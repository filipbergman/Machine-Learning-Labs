{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Programming Assignment #6: Recurrent Neural Networks\n",
    "Author: Pierre Nugues"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Objectives"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The objectives of this assignment are to:\n",
    "* Write a program to recognize named entities in text\n",
    "* Learn how to manage a text data set\n",
    "* Apply recurrent neural networks to text\n",
    "* Know what word embeddings are\n",
    "* Write a short report on your experiments. This report is mandatory to pass the assignment."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Organization and location"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can work alone or collaborate with another student:\n",
    "* Each group will have to write Python programs to recognize named entities in text.\n",
    "* You will have to experiment different architectures, namely RNN and LSTM, and compare the results you obtained.\n",
    "* Each student will have to write an individual report on these experiments."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "source": [
    "import sys\n",
    "import regex as re\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "from scipy.spatial.distance import cosine\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import normalize\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense, Dropout, Lambda, TimeDistributed\n",
    "from keras.layers import LSTM, Bidirectional, SimpleRNN, BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.activations import softmax\n",
    "\n",
    "EPOCHS = 15\n",
    "LSTM_UNITS = 100"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Collecting a Dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. You will use a dataset from the CoNLL conferences that benchmark natural language processing systems and tasks. There were two conferences on named entity recognition: <a href=\"https://www.clips.uantwerpen.be/conll2002/ner/\">CoNLL 2002</a> (Spanish and Dutch) and <a href=\"https://www.clips.uantwerpen.be/conll2003/ner/\">CoNLL 2003</a> (English and German). In this assignment, you will work on the English dataset. Read the description of the task.\n",
    "2. The datasets are protected by a license and you normally need to obtain it to reconstruct the data. As a shortcut, your teacher created a local copy in Canvas. Please use it. See the link in the Canvas description of the lab.\n",
    "3. Alternatively, you can try to find the dataset on github (type conll2003 in the search box) or use the Google dataset search: <a href=\"https://toolbox.google.com/datasetsearch\">https://toolbox.google.com/datasetsearch</a>, but some programmers may have changed the annotation, which could be misleading. \n",
    "4. The dataset comes in the form of three files: a training set, a development set, and a test set. <!--, named:\n",
    "    <tt>eng.train</tt>, <tt>eng.testa</tt> (validation), and <tt>eng.testb</tt> (test).-->"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Reading the Corpus"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "You will read the corpus with the cells below. The functions will enable you to load the files in the form of a list of dictionaries."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "source": [
    "BASE_DIR = ''"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "source": [
    "def load_conll2003_en():\n",
    "    train_file = BASE_DIR + 'NER-data/eng.train'\n",
    "    dev_file = BASE_DIR + 'NER-data/eng.valid'\n",
    "    test_file = BASE_DIR + 'NER-data/eng.test'\n",
    "    column_names = ['form', 'ppos', 'pchunk', 'ner']\n",
    "    train_sentences = open(train_file, encoding='utf8').read().strip()\n",
    "    dev_sentences = open(dev_file, encoding='utf8').read().strip()\n",
    "    test_sentences = open(test_file, encoding='utf8').read().strip()\n",
    "    return train_sentences, dev_sentences, test_sentences, column_names"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "source": [
    "train_sentences, dev_sentences, test_sentences, column_names = load_conll2003_en()\n",
    "train_sentences[:100]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'-DOCSTART- -X- O O\\n\\nEU NNP I-NP I-ORG\\nrejects VBZ I-VP O\\nGerman JJ I-NP I-MISC\\ncall NN I-NP O\\nto TO '"
      ]
     },
     "metadata": {},
     "execution_count": 207
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "source": [
    "class Token(dict):\n",
    "    pass\n",
    "\n",
    "\n",
    "class CoNLLDictorizer:\n",
    "\n",
    "    def __init__(self, column_names, sent_sep='\\n\\n', col_sep=' +'):\n",
    "        self.column_names = column_names\n",
    "        self.sent_sep = sent_sep\n",
    "        self.col_sep = col_sep\n",
    "\n",
    "    def fit(self):\n",
    "        pass\n",
    "\n",
    "    def transform(self, corpus):\n",
    "        corpus = corpus.strip()\n",
    "        sentences = re.split(self.sent_sep, corpus)\n",
    "        return list(map(self._split_in_words, sentences))\n",
    "\n",
    "    def fit_transform(self, corpus):\n",
    "        return self.transform(corpus)\n",
    "\n",
    "    def _split_in_words(self, sentence):\n",
    "        rows = re.split('\\n', sentence)\n",
    "        return [Token(dict(zip(self.column_names,\n",
    "                               re.split(self.col_sep, row))))\n",
    "                for row in rows]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "source": [
    "conll_dict = CoNLLDictorizer(column_names, col_sep=' +')\n",
    "train_dict = conll_dict.transform(train_sentences)\n",
    "dev_dict = conll_dict.transform(dev_sentences)\n",
    "test_dict = conll_dict.transform(test_sentences)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "source": [
    "train_dict[0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'form': '-DOCSTART-', 'ppos': '-X-', 'pchunk': 'O', 'ner': 'O'}]"
      ]
     },
     "metadata": {},
     "execution_count": 210
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "source": [
    "print('\\n'.join(map(str, train_dict[1])))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'form': 'EU', 'ppos': 'NNP', 'pchunk': 'I-NP', 'ner': 'I-ORG'}\n",
      "{'form': 'rejects', 'ppos': 'VBZ', 'pchunk': 'I-VP', 'ner': 'O'}\n",
      "{'form': 'German', 'ppos': 'JJ', 'pchunk': 'I-NP', 'ner': 'I-MISC'}\n",
      "{'form': 'call', 'ppos': 'NN', 'pchunk': 'I-NP', 'ner': 'O'}\n",
      "{'form': 'to', 'ppos': 'TO', 'pchunk': 'I-VP', 'ner': 'O'}\n",
      "{'form': 'boycott', 'ppos': 'VB', 'pchunk': 'I-VP', 'ner': 'O'}\n",
      "{'form': 'British', 'ppos': 'JJ', 'pchunk': 'I-NP', 'ner': 'I-MISC'}\n",
      "{'form': 'lamb', 'ppos': 'NN', 'pchunk': 'I-NP', 'ner': 'O'}\n",
      "{'form': '.', 'ppos': '.', 'pchunk': 'O', 'ner': 'O'}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluating your Models"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "You will train the models with the traiing set and the test set to evaluate them. For this, you will apply the `conlleval` script that will compute the harmonic mean of the precision and recall: F1. \n",
    "\n",
    "`conlleval` was written in Perl and you have a local copy of this script in `/usr/local/cs/EDAN95/datasets/ner/bin`. Some people rewrote it in Python and you will use such such a translation in this lab. The line below installs it."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "source": [
    "#!pip install conlleval\n",
    "#import conlleval"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Collecting the Embeddings"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "You will represent the words with the GloVe embeddings:\n",
    "1. Either:\n",
    "    * Download the GloVe embeddings 6B from <a href=\"https://nlp.stanford.edu/projects/glove/\">https://nlp.stanford.edu/projects/glove/</a> and keep the 100d vectors; or\n",
    "    * Use the local copy of this dataset in Canvas\n",
    "2. Apply the function below that reads GloVe embeddings and store them in a dictionary, where the keys will be the words and the values, the embedding vectors."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "source": [
    "embedding_file = 'glove.6B.100d.txt'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "source": [
    "def read_embeddings(file):\n",
    "    \"\"\"\n",
    "    Return the embeddings in the from of a dictionary\n",
    "    :param file:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    embeddings = {}\n",
    "    glove = open(file, encoding='utf8')\n",
    "    for line in glove:\n",
    "        values = line.strip().split()\n",
    "        word = values[0]\n",
    "        vector = np.array(values[1:], dtype='float32')\n",
    "        embeddings[word] = vector\n",
    "    glove.close()\n",
    "    return embeddings"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "source": [
    "# We read the embeddings\n",
    "embeddings_dict = read_embeddings(embedding_file)\n",
    "embedded_words = sorted(list(embeddings_dict.keys()))\n",
    "print('# words in embedding dictionary:', len(embedded_words))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "# words in embedding dictionary: 400000\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Using a cosine similarity, write a `closest(target_word, embeddings, count=10)` that computes the 10 closest words to the words _table_, _france_, and _sweden_."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "source": [
    "# Write your code here\n",
    "def closest(target_word, embeddings, count=10):\n",
    "    cosine_dict = {}\n",
    "    target_vect = embeddings[target_word]\n",
    "    for word in embeddings:\n",
    "        cosine_dict[word] = np.dot(embeddings[word], target_vect) / np.dot(norm(embeddings[word]), norm(target_vect))\n",
    "    sort_dict = sorted(cosine_dict.items(), key=lambda x: x[1], reverse = True)\n",
    "   \n",
    "    print(sort_dict[:10])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "source": [
    "closest('france', embeddings_dict)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[('france', 0.99999994), ('belgium', 0.8076422), ('french', 0.8004377), ('britain', 0.79505277), ('spain', 0.7557464), ('paris', 0.74815863), ('germany', 0.729408), ('italy', 0.71636367), ('europe', 0.709714), ('netherlands', 0.70726615)]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "source": [
    "closest('sweden', embeddings_dict)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[('sweden', 1.0), ('denmark', 0.8624401), ('norway', 0.807325), ('finland', 0.7906495), ('netherlands', 0.7468465), ('austria', 0.74668366), ('switzerland', 0.72333944), ('germany', 0.71736264), ('swedish', 0.71072894), ('belgium', 0.70818645)]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Extracting the $\\mathbf{X}$ and $\\mathbf{Y}$ Lists of Symbols"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Write a `build_sequences(corpus_dict, key_x='form', key_y='ner', tolower=True)` function that, for each sentence, returns the $\\mathbf{x}$ and $\\mathbf{y}$ lists of symbols consisting of words and NER tags."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "For the second sentence of the training set, you should have:<br/>\n",
    "<tt>x = ['eu', 'rejects', 'german', 'call', 'to', 'boycott', 'british', 'lamb', '.']</tt><br/>\n",
    "<tt>y = ['I-ORG', 'O', 'I-MISC', 'O', 'O', 'O', 'I-MISC', 'O', 'O']</tt><br/>\n",
    "Some datasets you may find on the web use a different NER tagset, where <tt>I-</tt> is\n",
    "replaced with <tt>B-</tt>, like <tt>B-ORG</tt> instead of <tt>I-ORG</tt>. This will not change the final results."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "source": [
    "# Write your code\n",
    "def build_sequences(corpus_dict, key_x='form', key_y='ner', tolower=True):\n",
    "    x = []\n",
    "    y = []\n",
    "    for i, sentence in enumerate(corpus_dict):\n",
    "        x.append([])\n",
    "        y.append([])\n",
    "        for word in sentence:\n",
    "            x[i].append(word[key_x])\n",
    "            y[i].append(word[key_y])\n",
    "    return x,y"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Apply this function to your datasets so that you create $\\mathbf{X}_\\text{train_symbs}$ and $\\mathbf{Y}_\\text{train_symbs}$ lists of lists consisting of words and NER tags."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "source": [
    "X_train_symbs, Y_train_symbs = build_sequences(train_dict, key_x='form', key_y='ner')\n",
    "X_dev_symbs, Y_dev_symbs = build_sequences(dev_dict, key_x='form', key_y='ner')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "source": [
    "X_train_symbs[1]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.']"
      ]
     },
     "metadata": {},
     "execution_count": 222
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "source": [
    "Y_train_symbs[1]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['I-ORG', 'O', 'I-MISC', 'O', 'O', 'O', 'I-MISC', 'O', 'O']"
      ]
     },
     "metadata": {},
     "execution_count": 223
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Vocabulary"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create a vocabulary of all the words observed in the training set and the words in GloVe. You should find 402,595 different words. You will proceed in two steps.\n",
    "\n",
    "First extract the list of unique words from the CoNLL training set and the list of NER tags. You will sort them"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "source": [
    "# Write your code: List of words and tags in CoNLL\n",
    "words_non_unique = [word.lower() for sentece in X_train_symbs for word in sentece]\n",
    "print(len(words_non_unique))\n",
    "words = np.unique(words_non_unique)\n",
    "ner_non_unique = [word for sentece in Y_train_symbs for word in sentece]\n",
    "ner = np.unique(ner_non_unique)\n",
    "words = sorted(words)\n",
    "ner = sorted(ner)\n",
    "\n",
    "# Development\n",
    "words_non_unique_dev = [word.lower() for sentece in X_dev_symbs for word in sentece]\n",
    "words_dev = np.unique(words_non_unique_dev)\n",
    "ner_non_unique_dev = [word for sentece in Y_dev_symbs for word in sentece]\n",
    "ner_dev = np.unique(ner_non_unique_dev)\n",
    "words_dev = sorted(words_dev)\n",
    "ner_dev = sorted(ner_dev)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "204567\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "source": [
    "print('# words seen in training corpus:', len(words))\n",
    "print('# NER tags seen:', len(ner))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "# words seen in training corpus: 21010\n",
      "# NER tags seen: 8\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then, merge the list of unique CoNLL words with the words in the embedding file. You will sort this list"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "source": [
    "# Write your code: Add vocabulary of embedded words\n",
    "vocabulary_words = np.unique(np.concatenate((np.array(embedded_words), words), axis=0))\n",
    "vocabulary_words_dev = np.unique(np.concatenate((np.array(embedded_words), words_dev), axis=0))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "source": [
    "print('# words in the vocabulary: embeddings and corpus:', len(vocabulary_words))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "# words in the vocabulary: embeddings and corpus: 402595\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Index"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create indices `word2idx`, `ner2idx` and inverted indices `idx2word`, `idx2ner` for the words and the NER: i.e. you will associate each word with a number. You will use index 0 for the padding symbol and 1 for unknown words. This means that your first word will start at index 2."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "source": [
    "# Write your code:\n",
    "word2idx = {}\n",
    "for i, word in enumerate(vocabulary_words):\n",
    "    word2idx[word] = i+2\n",
    "idx2word = {idx: word for word, idx in word2idx.items()}\n",
    "ner2idx = {}\n",
    "for i, nert in enumerate(ner):\n",
    "    ner2idx[nert] = i+2\n",
    "idx2ner = {idx: nert for nert, idx in ner2idx.items()}\n",
    "\n",
    "\n",
    "word2idx_dev = {}\n",
    "for i, word in enumerate(vocabulary_words_dev):\n",
    "    word2idx_dev[word] = i+2\n",
    "idx2word_dev = {idx: word for word, idx in word2idx_dev.items()}\n",
    "ner2idx_dev = {}\n",
    "for i, nert in enumerate(ner):\n",
    "    ner2idx_dev[nert] = i+2\n",
    "idx2ner_dev = {idx: nert for nert, idx in ner2idx_dev.items()}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The word indices"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "source": [
    "print(list(word2idx.items())[:25])      "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[('!', 2), ('!!', 3), ('!!!', 4), ('!!!!', 5), ('!!!!!', 6), ('!?', 7), ('!?!', 8), ('\"', 9), ('#', 10), ('##', 11), ('###', 12), ('#a', 13), ('#aabccc', 14), ('#b', 15), ('#c', 16), ('#cc', 17), ('#ccc', 18), ('#cccccc', 19), ('#ccccff', 20), ('#d', 21), ('#daa', 22), ('#dcdcdc', 23), ('#e', 24), ('#f', 25), ('#faf', 26)]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The NER tag indices"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "source": [
    "list(ner2idx.items())"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('B-LOC', 2),\n",
       " ('B-MISC', 3),\n",
       " ('B-ORG', 4),\n",
       " ('I-LOC', 5),\n",
       " ('I-MISC', 6),\n",
       " ('I-ORG', 7),\n",
       " ('I-PER', 8),\n",
       " ('O', 9)]"
      ]
     },
     "metadata": {},
     "execution_count": 230
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Embedding Matrix"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create a matrix of dimensions $(M, N)$, where $M$ will be the size of the vocabulary: The unique words in the training set and the words in GloVe, and $N$, the dimension of the embeddings.\n",
    "The padding symbol and the unknown word symbol will be part of the vocabulary at respectively index 0 and 1. \n",
    "\n",
    "Initialize the matrix with random values with the `np.random.uniform()`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "source": [
    "# Write your code here\n",
    "embedding_matrix = np.full((len(vocabulary_words)+2,len(embeddings_dict['hello'])),np.random.uniform())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The shape of your matrix should be: (402597, 100)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "source": [
    "embedding_matrix.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(402597, 100)"
      ]
     },
     "metadata": {},
     "execution_count": 232
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Fill the matrix with the GloVe embeddings when available. You will use the indices from the previous section. You will call `out_of_embeddings` the list of words in CoNLL, but not in the embedding list."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "source": [
    "# Write your code\n",
    "out_of_embeddings = []\n",
    "for i, word in enumerate(vocabulary_words):\n",
    "    if idx2word[i+2] not in embeddings_dict:\n",
    "         out_of_embeddings.append(idx2word[i+2])\n",
    "    else:\n",
    "        embedding_matrix[i+2] = embeddings_dict[idx2word[i+2]]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "source": [
    "len(out_of_embeddings)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2595"
      ]
     },
     "metadata": {},
     "execution_count": 234
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "source": [
    "out_of_embeddings[-10:]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['zelezarny',\n",
       " 'zhilan',\n",
       " 'zieger',\n",
       " 'zighayer',\n",
       " 'zilinskiene',\n",
       " 'zirka-nibas',\n",
       " 'zuleeg',\n",
       " 'zundra',\n",
       " 'zwingmann',\n",
       " 'zyrecha']"
      ]
     },
     "metadata": {},
     "execution_count": 235
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Embeddings of the padding symbol, idx 0, random numbers"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "source": [
    "embedding_matrix[0][:10]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.6839791, 0.6839791, 0.6839791, 0.6839791, 0.6839791, 0.6839791,\n",
       "       0.6839791, 0.6839791, 0.6839791, 0.6839791])"
      ]
     },
     "metadata": {},
     "execution_count": 236
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Embeddings of the word _table_, the GloVe values"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "source": [
    "embedding_matrix[word2idx['table']][:10]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([-0.61453998,  0.89692998,  0.56770998,  0.39102   , -0.22437   ,\n",
       "        0.49035001,  0.10868   ,  0.27410999, -0.23833001, -0.52152997])"
      ]
     },
     "metadata": {},
     "execution_count": 237
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Embeddings of _zwingmann_, a word in CoNLL 2003, but not in GloVe, random numbers"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "source": [
    "embedding_matrix[word2idx['zwingmann']][:10]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.6839791, 0.6839791, 0.6839791, 0.6839791, 0.6839791, 0.6839791,\n",
       "       0.6839791, 0.6839791, 0.6839791, 0.6839791])"
      ]
     },
     "metadata": {},
     "execution_count": 238
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating the $\\mathbf{X}$ and $\\mathbf{Y}$ Sequences"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "You will now create the input and output sequences with numerical indices. First, convert the $\\mathbf{X}_\\text{_train_symbs}$ and $\\mathbf{Y}_\\text{_train_symbs}$ lists of symbols in lists of numbers using the indices you created. Call them `X_train_idx` and `Y_train_idx`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "source": [
    "# Write your code\n",
    "# We create the parallel sequences of indexes\n",
    "#print(X_train_symbs)\n",
    "#print(out_of_embeddings)\n",
    "X_train_idx = []\n",
    "Y_train_idx = []\n",
    "for sentence in X_train_symbs:\n",
    "    t = []\n",
    "    for word in sentence:\n",
    "        t.append(word2idx[word.lower()])\n",
    "    X_train_idx.append(t)\n",
    "for sentence in Y_train_symbs:\n",
    "    t = []\n",
    "    for nert in sentence:\n",
    "        t.append(ner2idx[nert])\n",
    "    Y_train_idx.append(t)\n",
    "\n",
    "X_dev_idx = []\n",
    "Y_dev_idx = []\n",
    "for sentence in X_dev_symbs:\n",
    "    t = []\n",
    "    for word in sentence:\n",
    "        t.append(word2idx_dev[word.lower()])\n",
    "    X_dev_idx.append(t)\n",
    "for sentence in Y_dev_symbs:\n",
    "    t = []\n",
    "    for nert in sentence:\n",
    "        t.append(ner2idx_dev[nert])\n",
    "    Y_dev_idx.append(t)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Word indices of the three first sentences"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "source": [
    "X_train_idx[:3]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[[935],\n",
       " [142143, 307143, 161836, 91321, 363368, 83766, 85852, 218260, 936],\n",
       " [284434, 79019]]"
      ]
     },
     "metadata": {},
     "execution_count": 240
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "NER tag indices of the three first sentences"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "source": [
    "Y_train_idx[:3]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[[9], [7, 9, 6, 9, 9, 9, 6, 9, 9], [8, 8]]"
      ]
     },
     "metadata": {},
     "execution_count": 241
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, pad the sentences using the `pad_sequences` function from Keras. As maximum length and `maxlen` argument, you will use 150 or greater. What matters is that you have a length that is larger than the maximum length observed in your training and development corpora. After padding, the second sentence you look like (the indices are not necessarily the same).\n",
    "```\n",
    "x = [142143 307143 161836  91321 363368  83766  85852 218260    936      0\n",
    "      0      0      0      0      0      0      0      0      0      0\n",
    "      0      0      0      0      0      0      0      0      0      0\n",
    "      0      0      0      0      0      0      0      0      0      0\n",
    "      0      0      0      0      0      0      0      0      0      0\n",
    "      0      0      0      0      0      0      0      0      0      0\n",
    "      0      0      0      0      0      0      0      0      0      0\n",
    "      0      0      0      0      0      0      0      0      0      0\n",
    "      0      0      0      0      0      0      0      0      0      0\n",
    "      0      0      0      0      0      0      0      0      0      0\n",
    "      0      0      0      0      0      0      0      0      0      0\n",
    "      0      0      0      0      0      0      0      0      0      0\n",
    "      0      0      0      0      0      0      0      0      0      0\n",
    "      0      0      0      0      0      0      0      0      0      0\n",
    "      0      0      0      0      0      0      0      0      0      0]\n",
    "y = [7 9 6 9 9 9 6 9 9 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    " 0 0]\n",
    "```\n",
    "\n",
    "You will call the results `X_train_padded` and `Y_train_padded`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "source": [
    "# Write your code\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "X_train_padded = pad_sequences(X_train_idx, value=0, maxlen=150, padding='post')\n",
    "Y_train_padded = pad_sequences(Y_train_idx, value=0, maxlen=150, padding='post')\n",
    "\n",
    "X_dev_padded = pad_sequences(X_dev_idx, value=0, maxlen=150, padding='post')\n",
    "Y_dev_padded = pad_sequences(Y_dev_idx, value=0, maxlen=150, padding='post')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "source": [
    "X_train_padded[1]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([142143, 307143, 161836,  91321, 363368,  83766,  85852, 218260,\n",
       "          936,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0], dtype=int32)"
      ]
     },
     "metadata": {},
     "execution_count": 243
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "source": [
    "Y_train_padded[1]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([7, 9, 6, 9, 9, 9, 6, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)"
      ]
     },
     "metadata": {},
     "execution_count": 244
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Convert the indices in the $\\mathbf{Y}_\\text{train_padded}$ vector into one-hot encoded vectors. Call the result `Y_train_padded_vectorized`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "source": [
    "# Write your code\n",
    "from keras.utils.np_utils import to_categorical\n",
    "# The number of POS classes and 0 (padding symbol)\n",
    "# and a possible new POS symbol in the test set\n",
    "print(Y_train_padded.shape)\n",
    "Y_train_padded_vectorized = []\n",
    "temp_vec = []\n",
    "for sentence in Y_train_padded:\n",
    "    temp_vec = np.zeros((sentence.size, sentence.max()+1))\n",
    "    temp_vec[np.arange(sentence.size),sentence] = 1\n",
    "    Y_train_padded_vectorized.append(temp_vec)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(14987, 150)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "source": [
    "Y_train_padded_vectorized[1][:10]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "metadata": {},
     "execution_count": 246
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Do the same for the development set: Build the sequences, map them to indices, pad them, and create the $\\mathbf{Y}$ vectors"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "source": [
    "# Write your code\n",
    "Y_dev_padded_vectorized = []\n",
    "temp_vec_dev = []\n",
    "for sentence in Y_dev_padded:\n",
    "    temp_vec_dev = np.zeros((sentence.size, sentence.max()+1))\n",
    "    temp_vec_dev[np.arange(sentence.size),sentence] = 1\n",
    "    Y_dev_padded_vectorized.append(temp_vec_dev)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Building a Simple Recurrent Neural Network"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create a simple recurrent network and train a model (`model1`) with the training set. As layers, you will use `Embedding`, `SimpleRNN`, and `Dense`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "source": [
    "# Write your code\n",
    "from keras.initializers import Constant\n",
    "model1 = Sequential([\n",
    "    Embedding(len(vocabulary_words) + 2, 100, \n",
    "    embeddings_initializer = Constant(embedding_matrix),\n",
    "    trainable = False, \n",
    "    mask_zero = True),\n",
    "    SimpleRNN(units=LSTM_UNITS, return_sequences=True),\n",
    "    Dense(10, activation=\"softmax\")])\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Compile your network. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "source": [
    "# Write your code\n",
    "model1.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer='adam',\n",
    "              metrics=[\"accuracy\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "source": [
    "model1.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_19 (Embedding)     (None, None, 100)         40259700  \n",
      "_________________________________________________________________\n",
      "simple_rnn_13 (SimpleRNN)    (None, None, 100)         20100     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, None, 10)          1010      \n",
      "=================================================================\n",
      "Total params: 40,280,810\n",
      "Trainable params: 21,110\n",
      "Non-trainable params: 40,259,700\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Write a callback to store your best model using the validation loss. Name your file: `simple_rnn.keras`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "source": [
    "# Write your code\n",
    "from tensorflow import keras\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"simple_rnn.keras\",\n",
    "        save_best_only=True,\n",
    "        monitor=\"val_loss\")\n",
    "]\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "source": [
    "print(X_train_padded.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(14987, 150)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Fit it"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "source": [
    "# Write your code\n",
    "\n",
    "\n",
    "history = model1.fit(\n",
    "    x=list(X_train_padded),\n",
    "    y=list(Y_train_padded_vectorized),\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(list(X_dev_padded), list(Y_dev_padded_vectorized)),\n",
    "    callbacks=callbacks)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 1 array(s), but instead got the following list of 14987 arrays: [array([[935],\n       [  0],\n       [  0],\n       [  0],\n       [  0],\n       [  0],\n       [  0],\n       [  0],\n       [  0],\n       [  0],\n       [  0],\n       [  0],\n       [  0],\n       [  0],\n   ...",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-314-6bae0fd49179>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_train_padded_vectorized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     callbacks=callbacks)\n\u001b[0m",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1152\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    107\u001b[0m                 \u001b[0;34m'Expected to see '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' array(s), '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0;34m'but instead got the following list of '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m                 str(len(data)) + ' arrays: ' + str(data)[:200] + '...')\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             raise ValueError(\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 1 array(s), but instead got the following list of 14987 arrays: [array([[935],\n       [  0],\n       [  0],\n       [  0],\n       [  0],\n       [  0],\n       [  0],\n       [  0],\n       [  0],\n       [  0],\n       [  0],\n       [  0],\n       [  0],\n       [  0],\n   ..."
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create a figure to show the training and validation losses and accuracies and comment on a possible overfit."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "source": [
    "# Write your code\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Reload your best model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Write your code\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "You will apply your network to one sentence."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sentence = 'The United States might collapsez'.lower().split()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "First convert the sentence into indices"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Write your code\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Sentence ['the', 'united', 'states', 'might', 'collapsez']\n",
      "Sentence word indexes [359698, 374678, 344404, 246008, 1]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Apply the prediction"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Write your code\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sent_ner_predictions.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1, 5, 10)"
      ]
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Decode the word and tag indices"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Write your code\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "the: O\n",
      "united: I-LOC\n",
      "states: I-LOC\n",
      "might: O\n",
      "collapsez /ukn: O\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluating your System"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "You will now evaluate the performance of your system on the whole test set. You will use the official script.\n",
    "<ol>\n",
    "    <li>Use the <tt>predict</tt> method to predict the tags of the whole test set\n",
    "    </li>\n",
    "    <li>Write your results in a file, where the two last columns will be the hand-annotated tag\n",
    "        and the predicted tag. The fields must be separated by a space and each line must end with a new line:\n",
    "        <tt>\\n</tt>.\n",
    "    </li>\n",
    "    <li>\n",
    "        If you save your results on a Windows machine, Python will use the default end-of-line sequence: <tt>\\r\\n</tt>.\n",
    "        You will then need either to convert your file or to modify the way you save your file.\n",
    "    </li>\n",
    "    <li>Apply <tt>conlleval</tt> to your output. Report the F1 result.<br/>\n",
    "        Be aware that <tt>conlleval</tt> was designed for Unix and will break\n",
    "    with Windows end-of-line conventions.</li>\n",
    "    <li>Try to improve your model by modifying some parameters, adding layers, adding\n",
    "        <tt>Bidirectional</tt>\n",
    "        and <tt>Dropout</tt>.\n",
    "    </li>\n",
    "    <li>\n",
    "        Evaluate your network again\n",
    "    </li>\n",
    "</ol>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "First translate the input part of the test set, the words, into lists of words, `X_test_symbs`, lists of indices, `X_test_idx`, and a matrix of indices, where you will pad the sequences: `X_test_padded`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The symbols"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Test\n",
    "X_test_symbs, Y_test_symbs = build_sequences(test_dict, key_x='form', key_y='ner')\n",
    "print('X_test:', X_test_symbs[1])\n",
    "print('Y_test', Y_test_symbs[1])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "X_test: ['soccer', '-', 'japan', 'get', 'lucky', 'win', ',', 'china', 'in', 'surprise', 'defeat', '.']\n",
      "Y_test ['O', 'O', 'I-LOC', 'O', 'O', 'O', 'O', 'I-PER', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The indices"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Write your code\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('X_test_idx:', X_test_idx[1])\n",
    "print('X_test_padded:', X_test_padded[1])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "X_test_idx: [338644, 679, 197600, 162137, 229067, 390518, 517, 100680, 190291, 350949, 120818, 936]\n",
      "X_test_padded: [338644    679 197600 162137 229067 390518    517 100680 190291 350949\n",
      " 120818    936      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_test_padded.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(3684, 150)"
      ]
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now predict the whole test set with `predict` and set the results in `Y_test_hat_probs`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Write your code\n",
    "# We evaluate on all the test corpus\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('Predictions', Y_test_hat_probs[1])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Predictions [[1.2249970e-08 3.3408359e-08 1.0807129e-06 ... 3.2240015e-03\n",
      "  7.2276657e-06 9.9319553e-01]\n",
      " [2.2210155e-10 3.4949341e-10 1.5463007e-07 ... 3.4067221e-04\n",
      "  2.0880318e-04 9.9902940e-01]\n",
      " [9.7668869e-09 3.8468118e-09 1.6969406e-07 ... 3.4166221e-02\n",
      "  1.7162025e-03 8.0466941e-03]\n",
      " ...\n",
      " [3.3347903e-15 4.3808078e-15 3.3322396e-12 ... 3.3078271e-05\n",
      "  7.4312666e-06 9.9995351e-01]\n",
      " [3.3347903e-15 4.3808078e-15 3.3322396e-12 ... 3.3078271e-05\n",
      "  7.4312666e-06 9.9995351e-01]\n",
      " [3.3347903e-15 4.3808078e-15 3.3322396e-12 ... 3.3078271e-05\n",
      "  7.4312666e-06 9.9995351e-01]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Extract the indices with the highest probabilities from the lists and convert them into NER values. Use the original length of each sentence to discard the padded part of `y` sequences. Add them with the `pner` key to the dictionaries in the `test_dict` list."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# write your code\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test_dict[1]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'form': 'SOCCER', 'ppos': 'NN', 'pchunk': 'I-NP', 'ner': 'O', 'pner': 'O'},\n",
       " {'form': '-', 'ppos': ':', 'pchunk': 'O', 'ner': 'O', 'pner': 'O'},\n",
       " {'form': 'JAPAN',\n",
       "  'ppos': 'NNP',\n",
       "  'pchunk': 'I-NP',\n",
       "  'ner': 'I-LOC',\n",
       "  'pner': 'I-LOC'},\n",
       " {'form': 'GET', 'ppos': 'VB', 'pchunk': 'I-VP', 'ner': 'O', 'pner': 'O'},\n",
       " {'form': 'LUCKY', 'ppos': 'NNP', 'pchunk': 'I-NP', 'ner': 'O', 'pner': 'O'},\n",
       " {'form': 'WIN', 'ppos': 'NNP', 'pchunk': 'I-NP', 'ner': 'O', 'pner': 'O'},\n",
       " {'form': ',', 'ppos': ',', 'pchunk': 'O', 'ner': 'O', 'pner': 'O'},\n",
       " {'form': 'CHINA',\n",
       "  'ppos': 'NNP',\n",
       "  'pchunk': 'I-NP',\n",
       "  'ner': 'I-PER',\n",
       "  'pner': 'I-LOC'},\n",
       " {'form': 'IN', 'ppos': 'IN', 'pchunk': 'I-PP', 'ner': 'O', 'pner': 'O'},\n",
       " {'form': 'SURPRISE', 'ppos': 'DT', 'pchunk': 'I-NP', 'ner': 'O', 'pner': 'O'},\n",
       " {'form': 'DEFEAT', 'ppos': 'NN', 'pchunk': 'I-NP', 'ner': 'O', 'pner': 'O'},\n",
       " {'form': '.', 'ppos': '.', 'pchunk': 'O', 'ner': 'O', 'pner': 'O'}]"
      ]
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ARCH = '1'\n",
    "outfile = 'test' + ARCH + '.out'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "column_names = ['form', 'ppos', 'pchunk', 'ner', 'pner']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def save(file, corpus_dict, column_names):\n",
    "    \"\"\"\n",
    "    Saves the corpus in a file\n",
    "    :param file:\n",
    "    :param corpus_dict:\n",
    "    :param column_names:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    with open(file, 'w', encoding='utf8') as f_out:\n",
    "        i += 1\n",
    "        for sentence in corpus_dict:\n",
    "            sentence_lst = []\n",
    "            for row in sentence:\n",
    "                items = map(lambda x: row.get(x, '_'), column_names)\n",
    "                sentence_lst += ' '.join(items) + '\\n'\n",
    "            sentence_lst += '\\n'\n",
    "            f_out.write(''.join(sentence_lst))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "save(outfile, test_dict, column_names)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "lines = open(outfile, encoding='utf8').read().splitlines()\n",
    "res = conlleval.evaluate(lines)\n",
    "baseline_score = res['overall']['chunks']['evals']['f1']\n",
    "baseline_score"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7406894162480513"
      ]
     },
     "metadata": {},
     "execution_count": 68
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Building a LSTM Network"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Create a simple LSTM network and train a model with the train set. As layers, you will use <tt>Embedding</tt>, <tt>LSTM</tt>, and <tt>Dense</tt>.\n",
    "2. Apply conlleval to your output. Report the F1 result.\n",
    "3. Try to improve your model by modifying some parameters, adding layers, adding <tt>Bidirectional</tt>, <tt>Dropout</tt>, possibly mixing <tt>SimpleRNN</tt>.\n",
    "4. Apply your network to the test set and report the accuracy you obtained. you need to reach a F1 of 82 to pass."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Write your code\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Compile it"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Write your code\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model2.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, None, 100)         40259700  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, None, 100)         0         \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, None, 200)        160800    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, None, 200)         0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, None, 10)          2010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,422,510\n",
      "Trainable params: 40,422,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Write a callback to store your best model. Call it `lstm.keras`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Write your code\n",
    "from tensorflow import keras\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Fit your model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Write your code\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/15\n",
      "469/469 [==============================] - 184s 385ms/step - loss: 0.0242 - accuracy: 0.9221 - val_loss: 0.0134 - val_accuracy: 0.9619\n",
      "Epoch 2/15\n",
      "469/469 [==============================] - 176s 375ms/step - loss: 0.0121 - accuracy: 0.9595 - val_loss: 0.0104 - val_accuracy: 0.9692\n",
      "Epoch 3/15\n",
      "469/469 [==============================] - 141s 302ms/step - loss: 0.0096 - accuracy: 0.9673 - val_loss: 0.0109 - val_accuracy: 0.9677\n",
      "Epoch 4/15\n",
      "469/469 [==============================] - 179s 383ms/step - loss: 0.0081 - accuracy: 0.9726 - val_loss: 0.0088 - val_accuracy: 0.9741\n",
      "Epoch 5/15\n",
      "469/469 [==============================] - 178s 380ms/step - loss: 0.0070 - accuracy: 0.9763 - val_loss: 0.0083 - val_accuracy: 0.9757\n",
      "Epoch 6/15\n",
      "469/469 [==============================] - 175s 372ms/step - loss: 0.0063 - accuracy: 0.9785 - val_loss: 0.0078 - val_accuracy: 0.9770\n",
      "Epoch 7/15\n",
      "469/469 [==============================] - 141s 300ms/step - loss: 0.0056 - accuracy: 0.9810 - val_loss: 0.0078 - val_accuracy: 0.9775\n",
      "Epoch 8/15\n",
      "469/469 [==============================] - 144s 307ms/step - loss: 0.0050 - accuracy: 0.9830 - val_loss: 0.0080 - val_accuracy: 0.9775\n",
      "Epoch 9/15\n",
      "469/469 [==============================] - 147s 313ms/step - loss: 0.0046 - accuracy: 0.9844 - val_loss: 0.0086 - val_accuracy: 0.9770\n",
      "Epoch 10/15\n",
      "469/469 [==============================] - 178s 379ms/step - loss: 0.0043 - accuracy: 0.9856 - val_loss: 0.0075 - val_accuracy: 0.9783\n",
      "Epoch 11/15\n",
      "469/469 [==============================] - 142s 303ms/step - loss: 0.0039 - accuracy: 0.9869 - val_loss: 0.0079 - val_accuracy: 0.9786\n",
      "Epoch 12/15\n",
      "469/469 [==============================] - 999s 2s/step - loss: 0.2659 - accuracy: 0.9863 - val_loss: 0.0080 - val_accuracy: 0.9781\n",
      "Epoch 13/15\n",
      "469/469 [==============================] - 136s 290ms/step - loss: 0.1949 - accuracy: 0.9880 - val_loss: 0.0086 - val_accuracy: 0.9784\n",
      "Epoch 14/15\n",
      "469/469 [==============================] - 134s 287ms/step - loss: 0.0032 - accuracy: 0.9892 - val_loss: 0.0081 - val_accuracy: 0.9786\n",
      "Epoch 15/15\n",
      "469/469 [==============================] - 135s 288ms/step - loss: 0.0030 - accuracy: 0.9893 - val_loss: 0.0078 - val_accuracy: 0.9789\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create a figure to show the training and validation losses and accuracies and comment on a possible overfit."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Write your code\n"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAuA0lEQVR4nO3de3xU1bn/8c+XcDOggIBUCBBUKiByM6KiVay2xcvBQrVCU8tFiqh4O8eftWpbTy3n57GeU+3R6qFVEUuLYoWftuINL7TVCuEqICgiSFQwRSUg18Dz+2PtJMMwSSZxJpMMz/v12q+Zvffaez97CM+sWXvttWVmOOecy15NMh2Ac8659PJE75xzWc4TvXPOZTlP9M45l+U80TvnXJbzRO+cc1nOE32WkzRX0phUl80kSeslnZuG/Zqk46L3D0r6STJl63CcQkkv1DXObCSpm6TtknIyHUs2kvejb3gkbY+ZzQV2A/ui+SvMbEb9R9VwSFoPTDCzl1K8XwN6mtnaVJWVlA+8DzQzs7KUBOpcLTXNdADuYGbWuvx9dUlNUlNPHq6h8L/HhsubbhoRSUMlFUv6kaRNwCOS2kn6s6QSSZ9F7/NitnlV0oTo/VhJf5N0d1T2fUnn1bFsD0nzJW2T9JKk+yX9voq4k4nxDkl/j/b3gqQOMesvk7RB0hZJt1bz+ZwqaVPsz39JIyQtj94PlvSGpM8lfSzpPknNq9jXNEm/iJn/P9E2H0kaH1f2AklLJJVK2ijp9pjV86PXz6OmidPKP9uY7YdIWihpa/Q6JNnPppaf85GSHonO4TNJc2LWXSRpaXQO70kaFi0/oJlM0u3l/86S8qMmrMslfQC8HC2fFf07bI3+Rk6I2f4wSf8V/Xtujf7GDovZV9OoXBtJD0Wf+YeSflH+7yrpOEmvRdv/U9LjiT4PV8kTfePzFeBIoDswkfBv+Eg03w3YCdxXzfanAGuADsBdwEOSVIeyfwAWAO2B24HLqjlmMjF+DxgHHAU0B24EkNQHeCDaf+foeHkkYGb/AL4Avh633z9E7/cBN0TncxpwDnBVNXETxTAsiucbQE8g/vrAF8APgLbABcCVkr4drTszem1rZq3N7I24fR8J/AX4dXRu/w38RVL7uHM46LNJoKbP+TFCU+AJ0b5+FcUwGJgO/J/oHM4E1ldxjETOAnoD34rm5xI+p6OAxUBsU+PdwEnAEMLf8U3A/gT7fBQoA44DBgLfBCZE6+4AXgDaEf4W/qcWsR6azMynBjwR/sOdG70fCuwBWlZTfgDwWcz8q4SmH4CxwNqYdbmAAV+pTVlCEikDcmPW/x74fZLnlCjG22LmrwKei97/FJgZs65V9BmcW8W+fwE8HL0/nJCEu1dR9npgdsy8AcdF76cBv4jePwzcGVPuq7FlE+z3HuBX0fv8qGzTmPVjgb9F7y8DFsRt/wYwtqbPpjafM3A0IaG2S1Duf8vjre7vL5q/vfzfOebcjqkmhrZRmTaEL6KdQP8E5So+J6AT4brUYTHrRwOvRO+nA1OBvFT9P8v2yWv0jU+Jme0qn5GUK+l/o5/CpYSmgraquvfCpvI3ZrYjetu6lmU7A5/GLAPYWFXASca4Keb9jpiYOsfu28y+ALZUdSxC7X2kpBbASGCxmW2I4vhq1JyxKYrjPwi1+5ocEAOwIe78TpH0StRkshWYlOR+y/e9IW7ZBqBLzHxVn80BavicuxL+zT5LsGlX4L0k402k4rORlCPpzqj5p5TKXwYdoqllEsfqDjQDPo6a2T4nfBkdFa2/CRCwQNLK+KY0dzBP9I1PfDepfwOOB04xsyOobCqoqjkmFT4GjpSUG7OsazXlv0yMH8fuOzpm+6oKm9kqQqI8jwObbSA0Aa0m9JY5ArilLjEQftHE+gPwNNDVzNoAD8bst6ZubR8RElusbsCHScQVr7rPeSPh36xtgu02AsdWsc8vCL/myn0lQZnYc/wecBGheasNoaZeHsM/gV3VHCs2nt1ABzNrG01HmNkJAGa2ycx+aGadgSuA36iOXV0PFZ7oG7/DCT+HP4/ae3+W7gNGNeQi4HZJzSWdBvxLmmJ8ErhQ0hkKF05/Ts1/t38AriUkullxcZQC2yX1Aq5MMoYngLGS+kRfNPHxH06oLe+K2ru/F7OuhNBkckwV+34W+Kqk70lqKulSoA/w5yRji48j4edsZh8T2s5/E120bSap/IvgIWCcpHMkNZHUJfp8AJYCo6LyBcDFScSwm/CrK5fwq6k8hv2EZrD/ltQ5qv2fFv36Iqbcx4Q2+P+SdEQU07GSzgKQdIkqLzJ/Rvii2Yerkif6xu8e4DBCbekfwHP1dNxCwgXNLYR28ccJ/8ETuYc6xmhmK4GrCcn7Y8J/7OIaNvsj4XrGy2b2z5jlNxKS8Dbgt1HMycQwNzqHl4G10Wusq4CfS9pGuKbwRMy2O4ApwN+jZohT4/a9BbiQUBvfQmiWuDAu7mTdQ/Wf82XAXsKvmk8I1ygwswWEi72/ArYCr1H5K+MnhBr4Z8C/c+AvpESmE35RfQisiuKIdSPwFrAQ+BT4TxLnoR8QLjyvio79JOE6A8DJwJsK95s8DVxnZu/XENchzW+YcikRdXFbbWZp/0XhnKsdr9G7OpF0cvRzuknU/fAiYE6Gw3LOJeB3xrq6+grwFOHCaDFwpZktyWxIzrlEvOnGOeeynDfdOOdclmuQTTcdOnSw/Pz8TIfhnHONxqJFi/5pZh0TrWuQiT4/P5+ioqJMh+Gcc42GpPg7rCt4041zzmU5T/TOOZflPNE751yWSyrRSxomaY2ktZJuTrC+naTZkpZLWiCpb8y66yStiEaZuz6FsTvnnEtCjYk+GuL0fsJogH2A0dHDIGLdAiw1s36EMSrujbbtC/wQGAz0JwxO1TN14TvnnKtJMjX6wYQHUKwzsz3ATMLt7rH6APMAzGw1kC+pE+GpM/8wsx0WniX5GjAiZdE751wWmDED8vOhSZPwOmNGTVvUTjKJvgsHPnShmAMfigCwjPCQh/LHknUnPOJrBXCmpPbR8K7nU8W45ZImSiqSVFRSUlK7s3DOuXqQjoQ8YwZMnAgbNoBZeJ04MbXJPplEn+jBDPHjJtwJtJO0FLgGWAKUmdnbhGFIXyQMmbqM8Ai6g3doNtXMCsysoGPHhH3+nXMuY9KVkG+9FXbsOHDZjh1heaokk+iLObAWnkd4Kk4FMys1s3FmNoDQRt8ReD9a95CZDTKzMwnjT7+bisCdc64+pSshf/BB7ZbXRTKJfiHQU1KP6Ak/owiD/VeQ1DZaB+FJ7fPNrDRad1T02o3QvPPHVAXvnHNVSXUzS7oScrf4B1PWsLwuakz00UXUycDzwNvAE2a2UtIkSZOiYr2BlZJWE3rnXBeziz9JWgU8A1xdxcOJnXMuZdLRzJKuhDxlCuTmHrgsNzcsT5UGOUxxQUGB+Vg3zrm6ys8PyT1e9+6wfn3d9ln+5RHbfJObC1OnQmFh3fYZu+9bbw2/Drp1C0m+tvuUtMjMChKt8ztjnXNJSXcXwFRKRzNLYWFI6t27gxReU5Hky/e9fj3s3x9eU7HPWA1y9ErnXMMSX5stbwqB1CelVOjWLXGN/ss2sxQWNszzrYnX6J1zNUpnF8B0/FKoj3bvxsQTvXOuRunqcZKuvunpbGZpjDzRO5dl0lFDTlePk3T+Ukh3u3dj4oneuSySrhpyuppC6uNmIeeJ3rmskq4acrqaQurjZiHnid65rJLOGnI6mkL8omn98ETvXAaluj29sdWQ/aJp/fBE71yGpKM9vTHWkP2iafp5oncuQ9LRnu41ZJeIj3XjXIY0aRJq8vGkULt1rjZ8rBvnvqTG1DfduXie6J2rQWPrm+5cPE/0ztWgsfVNdy6et9E7VwNvS3eNgbfRO/cleFu6a+w80TtXA29Ld42dJ3qXVdLRO8bb0l1j50+YclkjnU9BaqxPFnIOkqzRSxomaY2ktZJuTrC+naTZkpZLWiCpb8y6GyStlLRC0h8ltUzlCThXLp1jmzvXmNWY6CXlAPcD5wF9gNGS+sQVuwVYamb9gB8A90bbdgGuBQrMrC+QA4xKXfjOVfKxzZ1LLJka/WBgrZmtM7M9wEzgorgyfYB5AGa2GsiX1Cla1xQ4TFJTIBf4KCWROxfHe8c4l1gyib4LsDFmvjhaFmsZMBJA0mCgO5BnZh8CdwMfAB8DW83shS8btHOJeO8Y5xJLJtErwbL420fuBNpJWgpcAywByiS1I9T+ewCdgVaSvp/wINJESUWSikpKSpKN37kK3jvGucSSSfTFQNeY+Tziml/MrNTMxpnZAEIbfUfgfeBc4H0zKzGzvcBTwJBEBzGzqWZWYGYFHTt2rP2ZuEYlHd0gwcc2dy6RZLpXLgR6SuoBfEi4mPq92AKS2gI7ojb8CcB8MyuV9AFwqqRcYCdwDuBjGxzi0tkN0qXP7t2wfTvs2wft2kGzZpmOqH6VlcGuXQdPO3cmXl6X6YgjYO7c1MdeY6I3szJJk4HnCb1mHjazlZImResfBHoD0yXtA1YBl0fr3pT0JLAYKCM06UxN/Wm4xqS6bpCe6FNnzx4oLYVt20KC3ratcoqfT2bZ3r0H7r9VKzjyyJD0418TLSt/bdMm/JKrq7KykFx37DjwtaplqUrM+/Z9uX+Ppk2hZcuqp9zc8Bmlgw9q5uqdDxKWWjt3wurVsGIFrFwZXlesCL+UktG0KRx+eJhat658X9V8Tg589lnl9OmnB7/u2lX18SRo2/bgL4acnOQSeFlZ3T4nCQ47rPpkWz7VVK5Fi+T3VT41TfPtqdUNauZ3xrp6161b4iTk3SCrt3cvvPPOwQn9vfcqvyCbNYPjj4fTToNx40ICrSlxt2gRkmAq7dpV9ZdAoi+IDRvCOeTmhgR62GHQqVN4jV2W6H1Ny8oTctOmqT/PxsITvat3U6Yc2EYPNXeDLCsLzRCffx6mzz6rfJ9o+uKLsF35f2yp6vc1rY99f9hhoTaaaGrX7sD5Fi1q+8kE+/bBunWVibw8qb/zTmXzSZMm0LMn9OsHo0dD375wwglhWUNoO2/ZEo4+Okwu8zzRuxrNmBHazz/4INS6p0z5cm3phYWhxnfbbbBpU0iQZ50Fb74Jzz+fOHFv21b9PsubA8qnVq0q15lVNhXFvtblfXlN9bPPDm6zjteyZdVfArHT4YeHz7Y8ob/99oFNHz16hEQ+fHhI5n37hlp7Sx9MxCXJE72r1pftIVNWVtnc8NZbldO6dZVlPvsM5swJF+liE+KxxyZfe27d+std4Kut8qRf1S+KRL84/vlPWLu2cn18W3NeXkjkX/96ZQ29d+9wbs59GX4x1lUrPz9xe3r37qGfejkz+PDDA5P5W2+F2umePaFMTk5oWjjxxMqpTx846qhQq83JqY8zahjMwpfn55/D1q3QuXP4wnKurvxirKuzqgYE27ABHnywMqGvWBFqqeW6dAmJ/JvfrEzqvXp5c0M5KTQvtWoVPivn0skTvatWly5QXJx43ZVXhpr4iSfCd79bmdD79k1ff2DnXO15oncVyspCzfyNNyqnREm+WTO49lq45ppwcfZQ7bLmXGPhif4QtmUL/OMflUn9zTcruyUedVToiz1hQrg78tFHQ9JPRa8b51z98kR/iNi3L3Tfi62tv/NOWJeTA/37w9ixIbmfdlro0hdbU7/jjoyE7ZxLAU/0WerTTw+srS9YUNkXvWPHyjsnTzsNCgoO7HfunMsunuizyP798J//GZpZ1qwJy3Jywt2Tl11WWVs/5hhvV3fuUOKJPkvs2hWaXh5/PNxwM2ZMSOonn+y1decOdZ7os0BJCVx0UWiiadsWXn45DHTVrRsMHZrp6JxzmeaJvpFbvRouuAA2boTmzcOdluAP83DOVarH0UFcqr3ySmie2b4d2revHGqgXPnDPJxzhzZP9I3UtGlheIHOnUP/982bE5eraggD59yhwxN9I7N/fxjed9y40P7+97+HgceqemiHP8zDOeeJvhHZtQu+971wZ+qECfDss5UjHk6ZEh7eEaumh3k45w4NnugbiZKS0G3y8cdDX/mpUw98klBhYVjWvXvoI9+9e5j3C7HOOe910wiU96z56CN48kn4zncSlyss9MTunDtYUjV6ScMkrZG0VtLNCda3kzRb0nJJCyT1jZYfL2lpzFQq6foUn0NWi+1Z8+qrVSd555yrSo2JXlIOcD9wHtAHGC2pT1yxW4ClZtYP+AFwL4CZrTGzAWY2ADgJ2AHMTl342S2+Z80pp2Q6IudcY5RMjX4wsNbM1pnZHmAmcFFcmT7APAAzWw3kS+oUV+Yc4D0zS/BgOherqp41zjlXF8kk+i7Axpj54mhZrGXASABJg4HuQF5cmVHAH6s6iKSJkookFZWUlCQRVnaqrmeNc87VRTKJPtE4h/FPFL8TaCdpKXANsASoeMa9pObAcGBWVQcxs6lmVmBmBR07dkwirPqxdy889RT89a+hnTydaupZ45xzdZFMr5tioGvMfB7wUWwBMysFxgFIEvB+NJU7D1hsZlXcv9kw7dkDo0bB7OiqggTHHw8nnVQ5DRwYnpv6ZSXbs8Y552ormUS/EOgpqQfwIaEJ5nuxBSS1BXZEbfgTgPlR8i83mmqabRqiPXvg0kthzhy46y7o3RsWLQrTK6/AjBmhnARf/erByf+II5I/1iuvwMiRYVCyV1/1i67OudSqMdGbWZmkycDzQA7wsJmtlDQpWv8g0BuYLmkfsAq4vHx7SbnAN4Ar0hB/WuzZA5dcAk8/Df/zPzB5clh+4YWVZTZtqkz8ixbBa6/BH/4Q1knQs+eByX/QoMTJf9o0+OEPw5fFX/7iF12dc6kns/jm9swrKCiwoqKijBx79+6Q5J95Bu67D66+OvltN2+GxYsP/ALYGHMZuzz5S2HM+PKByPr2DdcA/KKrc66uJC0ys4JE6/zO2Bi7d4e28b/8Be6/H666qnbbd+oE550XpnKffHJg8n/xRdiy5cDt3nsvHNPvanXOpYPX6CO7doUk/+yz8MADMGlSeo6Tnx8eChKve3dYvz49x3TOZT+v0ddg165wMXTuXPjf/618MlM6VDU+vI8b75xLl0N+9Mpdu2DEiJDkp05Nb5IHHzfeOVf/DulEv3NneKj288/D734Xer+km48b75yrb4dsoi9P8i++GJL85ZfXvE0q+Ljxzrn6dki20e/YEZL8vHnw0ENh8LD65OPGO+fq0yGX6HfsgOHDQz/2Rx6BMWMyHZFzzqXXIZXov/gC/uVfwjADjz4Kl12W6Yiccy79DplE/8UXYQiD+fNh+nT4/vczHZFzztWPQyLRf/FFGBnyr38NSd7bx51zh5KsT/Tbt4ck/7e/we9/D6NHZzoi55yrX1md6Ldvh/PPD4/imzEjjC3vnHOHmqxN9Nu2hST/xhth+OBLL810RM45lxlZmehLS8MIkm++CX/8Yxh22DnnDlVZl+hLS2HYMFiwAGbOhIsvznREzjmXWVmV6LduDUm+qCg8YNufu+qcc1mU6EtL4VvfCg/3eOKJMCKlc865LBrUrGXLMEDYrFme5J1zLlbW1OibNw/NNc455w6UVI1e0jBJayStlXRzgvXtJM2WtFzSAkl9Y9a1lfSkpNWS3pZ0WipPwDnnXPVqTPSScoD7gfOAPsBoSX3iit0CLDWzfsAPgHtj1t0LPGdmvYD+wNupCNw551xykqnRDwbWmtk6M9sDzAQuiivTB5gHYGargXxJnSQdAZwJPBSt22Nmn6cq+PowY0Z4oHeTJuF1xoxMR+Scc7WTTKLvAmyMmS+OlsVaBowEkDQY6A7kAccAJcAjkpZI+p2kVokOImmipCJJRSUlJbU8jfSYMSM8Q3bDBjALrxMnerJ3zjUuySR6JVhmcfN3Au0kLQWuAZYAZYSLvYOAB8xsIPAFcFAbP4CZTTWzAjMr6NixY5Lhp9ett4YHlcTasSMsd865xiKZXjfFQNeY+Tzgo9gCZlYKjAOQJOD9aMoFis3szajok1SR6BuiDz6o3XLnnGuIkqnRLwR6SuohqTkwCng6tkDUs6Z5NDsBmG9mpWa2Cdgo6fho3TnAqhTFnnbdutVuuXPONUQ1JnozKwMmA88Tesw8YWYrJU2SNCkq1htYKWk1oXfOdTG7uAaYIWk5MAD4jxTGn1ZTpkBu7oHLcnPDcuecayxkFt/cnnkFBQVWVFSU6TCAcOH11ltDc023biHJ+xOqnHMNjaRFZlaQaF3W3BmbLoWFntidc41b1ox145xzLjFP9M45l+U80TvnXJbzRO+cc1nOE71zzmU5T/TOOZflPNE751yW80TvnHNZzhO9c85lOU/0zjmX5TzRO+dclvNE75xzWc4TvXPOZTlP9M45l+U80TvnXJbzRO+cc1nOE71zzmU5T/TOOZflPNE751yW80TvnHNZLqlEL2mYpDWS1kq6OcH6dpJmS1ouaYGkvjHr1kt6S9JSSUWpDN4551zNmtZUQFIOcD/wDaAYWCjpaTNbFVPsFmCpmY2Q1Csqf07M+rPN7J8pjNs551ySkqnRDwbWmtk6M9sDzAQuiivTB5gHYGargXxJnVIaqXPOuTpJJtF3ATbGzBdHy2ItA0YCSBoMdAfyonUGvCBpkaSJVR1E0kRJRZKKSkpKko3fOedcDZJJ9EqwzOLm7wTaSVoKXAMsAcqidaeb2SDgPOBqSWcmOoiZTTWzAjMr6NixY1LBO+ecq1mNbfSEGnzXmPk84KPYAmZWCowDkCTg/WjCzD6KXj+RNJvQFDT/S0funHMuKcnU6BcCPSX1kNQcGAU8HVtAUttoHcAEYL6ZlUpqJenwqEwr4JvAitSF75xzriY11ujNrEzSZOB5IAd42MxWSpoUrX8Q6A1Ml7QPWAVcHm3eCZgdKvk0Bf5gZs+l/jScc85VRWbxze2ZV1BQYEVF3uXeOeeSJWmRmRUkWud3xjrnXJbzRO+cc1nOE71zzmU5T/TOOZflPNE751yW80TvnHNZzhO9c85lOU/0zjmX5TzRO+dclvNE75xzWc4TvXPOZTlP9M45l+U80TvnXJbzRO+cc1nOE71zzmU5T/TOOZflPNE751yW80TvnHNZzhO9c85lOU/0zjmX5ZJK9JKGSVojaa2kmxOsbydptqTlkhZI6hu3PkfSEkl/TlXgzjnnklNjopeUA9wPnAf0AUZL6hNX7BZgqZn1A34A3Bu3/jrg7S8frnPOudpKpkY/GFhrZuvMbA8wE7gorkwfYB6Ama0G8iV1ApCUB1wA/C5lUTvnnEtaMom+C7AxZr44WhZrGTASQNJgoDuQF627B7gJ2F/dQSRNlFQkqaikpCSJsJxzziUjmUSvBMssbv5OoJ2kpcA1wBKgTNKFwCdmtqimg5jZVDMrMLOCjh07JhGWc865ZDRNokwx0DVmPg/4KLaAmZUC4wAkCXg/mkYBwyWdD7QEjpD0ezP7fgpid845l4RkavQLgZ6SekhqTkjeT8cWkNQ2WgcwAZhvZqVm9mMzyzOz/Gi7lz3JO+dc/aqxRm9mZZImA88DOcDDZrZS0qRo/YNAb2C6pH3AKuDyNMbsnHOuFmQW39yeeQUFBVZUVJTpMJxzrtGQtMjMChKt8ztjnXMuy3mid865LOeJ3jnnspwneuecy3Ke6J1zLst5onfOuSznid4557KcJ3rnnMtynuidcy7LeaJ3zrks54neOeeynCd655zLcp7onXMuy3mid865LOeJ3jnnspwneuecy3Ke6J1zLst5onfOuSznid4557JcjQ8Hd85l1t69eykuLmbXrl2ZDsU1AC1btiQvL49mzZolvU1SiV7SMOBeIAf4nZndGbe+HfAwcCywCxhvZisktQTmAy2iYz1pZj9LOjrnHMXFxRx++OHk5+cjKdPhuAwyM7Zs2UJxcTE9evRIersam24k5QD3A+cBfYDRkvrEFbsFWGpm/YAfEL4UAHYDXzez/sAAYJikU5OOzjnHrl27aN++vSd5hyTat29f6193ybTRDwbWmtk6M9sDzAQuiivTB5gHYGargXxJnSzYHpVpFk1Wqwidc57kXYW6/C0kk+i7ABtj5oujZbGWASOjIAYD3YG8aD5H0lLgE+BFM3uz1lE655yrs2QSfaKvj/ha+Z1AuyihXwMsAcoAzGyfmQ0gJP7BkvomPIg0UVKRpKKSkpIkw3fOxZsxA/LzoUmT8DpjRt33tWXLFgYMGMCAAQP4yle+QpcuXSrm9+zZU+22RUVFXHvttTUeY8iQIXUP0CUlmYuxxUDXmPk84KPYAmZWCowDUPhd8X40xZb5XNKrwDBgRfxBzGwqMBWgoKDAm3ecq4MZM2DiRNixI8xv2BDmAQoLa7+/9u3bs3TpUgBuv/12WrduzY033lixvqysjKZNE6eRgoICCgoKajzG66+/XvvAMmzfvn3k5ORkOoykJVOjXwj0lNRDUnNgFPB0bAFJbaN1ABOA+WZWKqmjpLZRmcOAc4HVKYveOXeAW2+tTPLlduwIy1Nl7Nix/Ou//itnn302P/rRj1iwYAFDhgxh4MCBDBkyhDVr1gDw6quvcuGFFwLhS2L8+PEMHTqUY445hl//+tcV+2vdunVF+aFDh3LxxRfTq1cvCgsLMQt1vmeffZZevXpxxhlncO2111bsN9b69ev52te+xqBBgxg0aNABXyB33XUXJ554Iv379+fmm28GYO3atZx77rn079+fQYMG8d577x0QM8DkyZOZNm0aAPn5+fz85z/njDPOYNasWfz2t7/l5JNPpn///nznO99hR/TBb968mREjRtC/f3/69+/P66+/zk9+8hPuvffeiv3eeuutB3wG6VZjjd7MyiRNBp4ndK982MxWSpoUrX8Q6A1Ml7QPWAVcHm1+NPBo1HOnCfCEmf05DefhnAM++KB2y+vqnXfe4aWXXiInJ4fS0lLmz59P06ZNeemll7jlllv405/+dNA2q1ev5pVXXmHbtm0cf/zxXHnllQf1BV+yZAkrV66kc+fOnH766fz973+noKCAK664gvnz59OjRw9Gjx6dMKajjjqKF198kZYtW/Luu+8yevRoioqKmDt3LnPmzOHNN98kNzeXTz/9FIDCwkJuvvlmRowYwa5du9i/fz8bN25MuO9yLVu25G9/+xsQmrV++MMfAnDbbbfx0EMPcc0113Dttddy1llnMXv2bPbt28f27dvp3LkzI0eO5LrrrmP//v3MnDmTBQsW1Ppzr6uk+tGb2bPAs3HLHox5/wbQM8F2y4GBXzJG51ySunULzTWJlqfSJZdcUtF0sXXrVsaMGcO7776LJPbu3ZtwmwsuuIAWLVrQokULjjrqKDZv3kxeXt4BZQYPHlyxbMCAAaxfv57WrVtzzDHHVPQbHz16NFOnTj1o/3v37mXy5MksXbqUnJwc3nnnHQBeeuklxo0bR25uLgBHHnkk27Zt48MPP2TEiBFASODJuPTSSyver1ixgttuu43PP/+c7du3861vfQuAl19+menTpwOQk5NDmzZtaNOmDe3bt2fJkiVs3ryZgQMH0r59+6SOmQp+Z6xzWWTKlAPb6AFyc8PyVGrVqlXF+5/85CecffbZzJ49m/Xr1zN06NCE27Ro0aLifU5ODmVlZUmVKW++qcmvfvUrOnXqxLJly9i/f39F8jazg7okVrXPpk2bsn///or5+P7qsec9duxY5syZQ//+/Zk2bRqvvvpqtfFNmDCBadOmsWnTJsaPH5/UOaWKj3XjXBYpLISpU6F7d5DC69SpdbsQm6ytW7fSpUvocV3enp1KvXr1Yt26daxfvx6Axx9/vMo4jj76aJo0acJjjz3Gvn37APjmN7/Jww8/XNGG/umnn3LEEUeQl5fHnDlzANi9ezc7duyge/furFq1it27d7N161bmzZtXZVzbtm3j6KOPZu/evcyI6dp0zjnn8MADDwDhom1paSkAI0aM4LnnnmPhwoUVtf/64oneuSxTWAjr18P+/eE1nUke4KabbuLHP/4xp59+ekVyTaXDDjuM3/zmNwwbNowzzjiDTp060aZNm4PKXXXVVTz66KOceuqpvPPOOxW172HDhjF8+HAKCgoYMGAAd999NwCPPfYYv/71r+nXrx9Dhgxh06ZNdO3ale9+97v069ePwsJCBg6suuX5jjvu4JRTTuEb3/gGvXr1qlh+77338sorr3DiiSdy0kknsXLlSgCaN2/O2WefzXe/+91677GjZH8W1aeCggIrKirKdBjONQhvv/02vXv3znQYGbV9+3Zat26NmXH11VfTs2dPbrjhhkyHVSv79+9n0KBBzJo1i549D7qkWSuJ/iYkLTKzhP1ZvUbvnGvwfvvb3zJgwABOOOEEtm7dyhVXXJHpkGpl1apVHHfccZxzzjlfOsnXhV+Mdc41eDfccEOjq8HH6tOnD+vWrcvY8b1G75xzWc4TvXPOZTlP9M45l+U80TvnXJbzRO+cq9LQoUN5/vnnD1h2zz33cNVVV1W7TXn36PPPP5/PP//8oDK33357RX/2qsyZM4dVq1ZVzP/0pz/lpZdeqkX0rpwneudclUaPHs3MmTMPWDZz5swqBxaL9+yzz9K2bds6HTs+0f/85z/n3HPPrdO+MiUdN5DVhXevdK4Ruf56iIaHT5kBA+CeexKvu/jii7ntttvYvXs3LVq0YP369Xz00UecccYZXHnllSxcuJCdO3dy8cUX8+///u8HbZ+fn09RUREdOnRgypQpTJ8+na5du9KxY0dOOukkIPSRnzp1Knv27OG4447jscceY+nSpTz99NO89tpr/OIXv+BPf/oTd9xxBxdeeCEXX3wx8+bN48Ybb6SsrIyTTz6ZBx54gBYtWpCfn8+YMWN45pln2Lt3L7NmzTrgrlUIwxlfdtllfPHFFwDcd999FQ8/ueuuu3jsscdo0qQJ5513HnfeeSdr165l0qRJlJSUkJOTw6xZs9i4cSN33303f/5zGIx38uTJFBQUMHbsWPLz8xk/fjwvvPACkydPZtu2bQedX25uLps3b2bSpEkV3S4feOAB5s6dS4cOHbjuuuuAMJxxp06dknqAS3W8Ru+cq1L79u0ZPHgwzz33HBBq85deeimSmDJlCkVFRSxfvpzXXnuN5cuXV7mfRYsWMXPmTJYsWcJTTz3FwoULK9aNHDmShQsXsmzZMnr37s1DDz3EkCFDGD58OL/85S9ZunQpxx57bEX5Xbt2MXbsWB5//HHeeustysrKKsaWAejQoQOLFy/myiuvTNg8VD6c8eLFi3n88ccrkmjscMbLli3jpptuAsJwxldffTXLli3j9ddf5+ijj67xcysfznjUqFEJzw+oGM542bJlLF68mBNOOIHLL7+cRx99FKBiOOPCFIxh4TV65xqRqmre6VTefHPRRRcxc+ZMHn74YQCeeOIJpk6dSllZGR9//DGrVq2iX79+Cffx17/+lREjRlQMFTx8+PCKdVUN91uVNWvW0KNHD7761a8CMGbMGO6//36uv/56IHxxAJx00kk89dRTB21/KA5nnDU1+lQ+J9M5V+nb3/428+bNY/HixezcuZNBgwbx/vvvc/fddzNv3jyWL1/OBRdccNCQvvHihwouN3bsWO677z7eeustfvazn9W4n5rG5yof6riqoZBjhzMuKiqqePZtOoczrs35lQ9n/Mgjj6RsOOOsSPTlz8ncsAHMKp+T6cneuS+vdevWDB06lPHjx1dchC0tLaVVq1a0adOGzZs3M3fu3Gr3ceaZZzJ79mx27tzJtm3beOaZZyrWVTXc7+GHH862bdsO2levXr1Yv349a9euBcIolGeddVbS53MoDmecFYm+Pp6T6dyhbPTo0SxbtoxRo0YB0L9/fwYOHMgJJ5zA+PHjOf3006vdftCgQVx66aUMGDCA73znO3zta1+rWFfVcL+jRo3il7/8JQMHDuS9996rWN6yZUseeeQRLrnkEk488USaNGnCpEmTkj6XQ3E446wYprhJk1CTjyeFMbmda8x8mOJDSzLDGR+SwxRX9TzMVD8n0znn0ildwxlnRa+b+npOpnPOpVO6hjNOqkYvaZikNZLWSro5wfp2kmZLWi5pgaS+0fKukl6R9LaklZKuS/UJQGaek+lcfWqITawuM+ryt1BjjV5SDnA/8A2gGFgo6WkzWxVT7BZgqZmNkNQrKn8OUAb8m5ktlnQ4sEjSi3HbpkRhoSd2l51atmzJli1baN++fZVdFN2hwczYsmVL0v35yyXTdDMYWGtm6wAkzQQuAmKTdR/g/0aBrJaUL6mTmX0MfBwt3ybpbaBL3LbOuWrk5eVRXFxMSUlJpkNxDUDLli3Jy8ur1TbJJPouwMaY+WLglLgyy4CRwN8kDQa6A3nA5vICkvKBgcCbiQ4iaSIwEaCbX0V1rkKzZs3o0aNHpsNwjVgybfSJfivGNxLdCbSTtBS4BlhCaLYJO5BaA38Crjez0kQHMbOpZlZgZgUdO3ZMJnbnnHNJSKZGXwx0jZnPAz6KLRAl73EACo2I70cTkpoRkvwMMzt44AnnnHNplUyNfiHQU1IPSc2BUcDTsQUktY3WAUwA5ptZaZT0HwLeNrP/TmXgzjnnkpPUnbGSzgfuAXKAh81siqRJAGb2oKTTgOnAPsKF1svN7DNJZwB/Bd4Cyu9RvcXMnq3heCXAhrqdUtp0AP6Z6SCS5LGmT2OKtzHFCo0r3oYYa3czS9ju3SCHQGiIJBVVdXtxQ+Oxpk9jircxxQqNK97GFCtkyRAIzjnnquaJ3jnnspwn+uRNzXQAteCxpk9jircxxQqNK97GFKu30TvnXLbzGr1zzmU5T/TOOZflPNFXo76GWU4lSTmSlkj6c6ZjqUl0o92TklZHn/FpmY6pKpJuiP4GVkj6o6TaDR+YZpIelvSJpBUxy46U9KKkd6PXdpmMMVYV8f4y+ltYHg173jaDIVZIFGvMuhslmaQOmYgtWZ7oq1c+zHJv4FTgakl9MhxTTa4D3s50EEm6F3jOzHoB/WmgcUvqAlwLFJhZX8KNg6MyG9VBpgHD4pbdDMwzs57AvGi+oZjGwfG+CPQ1s37AO8CP6zuoKkzj4FiR1JUwfPsH9R1QbXmir4aZfWxmi6P32wiJqEtmo6qapDzgAuB3mY6lJpKOAM4kDJGBme0xs88zGlT1mgKHSWoK5BI33lOmmdl84NO4xRcBj0bvHwW+XZ8xVSdRvGb2gpmVD4b4D8K4WhlXxWcL8CvgJg4e5LHB8USfpJqGWW4g7iH84TWGR6IfA5QAj0RNTb+T1CrTQSViZh8CdxNqbh8DW83shcxGlZTyZ0IQvR6V4XhqYzwwN9NBVEXScOBDM1uW6ViS4Yk+CckMs5xpki4EPjGzRZmOJUlNgUHAA2Y2EPiChtW0UCFq274I6AF0BlpJ+n5mo8pekm4lNJvOyHQsiUjKBW4FfprpWJLlib4GjWiY5dOB4ZLWAzOBr0v6fWZDqlYxUGxm5b+QniQk/oboXOB9Mysxs73AU8CQDMeUjM2SjgaIXj/JcDw1kjQGuBAotIZ7k8+xhC/9ZdH/tzxgsaSvZDSqaniir0ZjGmbZzH5sZnlmlk+4UPiymTXYWqeZbQI2Sjo+WnQODfcRkx8Ap0rKjf4mzqGBXjiO8zQwJno/Bvh/GYylRpKGAT8ChpvZjkzHUxUze8vMjjKz/Oj/WzEwKPqbbpA80VfvdOAyQu14aTSdn+mgssg1wAxJy4EBwH9kNpzEol8dTwKLCUNuN6GB3QIv6Y/AG8DxkoolXU548ts3JL1L6B1yZyZjjFVFvPcBhwMvRv/XHsxokJEqYm1UfAgE55zLcl6jd865LOeJ3jnnspwneuecy3Ke6J1zLst5onfOuSznid4557KcJ3rnnMty/x/sQc40aSjljQAAAABJRU5ErkJggg=="
     },
     "metadata": {
      "needs_background": "light"
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Reload your best model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Write your code\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Predict the NER sequence"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Write your code\n",
    "# We evaluate on all the test corpus\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Extract the indices of the highest probabilities from the lists and convert them into NER values. Add them with the `pner` key to the dictionaries in the `test_dict` list."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# write your code\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ARCH = '4'\n",
    "outfile = 'test' + ARCH + '.out'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "save(outfile, test_dict, column_names)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "lines = open(outfile, encoding='utf8').read().splitlines()\n",
    "res = conlleval.evaluate(lines)\n",
    "improved_score = res['overall']['chunks']['evals']['f1']\n",
    "improved_score"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.835102618542109"
      ]
     },
     "metadata": {},
     "execution_count": 80
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "You need to reach 82 to pass the assignment."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.3 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "interpreter": {
   "hash": "e134e05457d34029b6460cd73bbf1ed73f339b5b6d98c95be70b69eba114fe95"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}